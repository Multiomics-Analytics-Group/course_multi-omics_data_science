{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_AfYl8IOo-q"
      },
      "source": [
        "# Running Nextflow from Colab\n",
        "\n",
        "This is a guide with code to be able to run nf-core pipelines from colab notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQYm22prFIEP"
      },
      "source": [
        "## Installing Java\n",
        "\n",
        " Nextflow is a workflow management system that is written in the Groovy programming language. Groovy runs on the **Java Virtual Machine (JVM)**, which means that a Java Development Kit (JDK) or Java Runtime Environment (JRE) is a non-negotiable prerequisite.\n",
        " \n",
        " This code block uses the `apt` package manager (native to the Ubuntu-based Colab environment) to install Java.\n",
        " \n",
        " * `!apt update`: This refreshes the list of available packages from the software repositories.\n",
        " \n",
        " * `!apt install openjdk-17-jdk`: This installs version 17 of the open-source Java Development Kit.\n",
        " \n",
        " * `!export ...`: These commands attempt to set the `JAVA_HOME` and `PATH` environment variables. This is standard practice in a regular shell to tell the system where to find the Java executables. (Note: In Colab, each `!` command runs in a separate shell, so these `export` commands won't persist for subsequent cells, but the package installation itself often configures the default Java path correctly.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9g5_k5j2OnCg"
      },
      "outputs": [],
      "source": [
        "!apt update\n",
        "!apt install openjdk-17-jdk\n",
        "!export JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64\n",
        "!export PATH=$JAVA_HOME/bin:$PATH\n",
        "!source ~/.bashrc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovA2dn4BPIaY"
      },
      "source": [
        "## Installing Nextflow\n",
        "\n",
        "With Java installed, we can now install Nextflow. This cell uses the standard quick-install method provided by the Nextflow team.\n",
        "\n",
        "\n",
        "1.  `!wget -qO- https://get.nextflow.io | bash`: This command downloads the installer script from `get.nextflow.io` (`-qO-` means \\\"quiet\\\" and \\\"output to standard out\\\") and immediately pipes (`|`) the script's content to the `bash` interpreter, which executes it. This downloads the `nextflow` executable file into the current directory.\n",
        "\n",
        "2.  `!mv nextflow /usr/bin/nextflow`: We move the downloaded `nextflow` file from our local directory to `/usr/bin/`. This directory is part of the system's `PATH`, which allows us to run the `nextflow` command from any location.\n",
        "\n",
        "3.  `!chmod +x /usr/bin/nextflow`: This command modifies the file's permissions to make it executable (`+x`).\n",
        "\n",
        "4.  `!nextflow -v`: Finally, we run `nextflow -v` (version) to test the installation and confirm that the system can find and execute the program."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3Zl5FQNPMPB"
      },
      "outputs": [],
      "source": [
        "!wget -qO- https://get.nextflow.io | bash # Download Nextflow\n",
        "!mv nextflow /usr/bin/nextflow # Move to a path Colab can access\n",
        "!chmod +x /usr/bin/nextflow # Make it executable\n",
        "!nextflow -v # Test it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3wv9ZG-PRbU"
      },
      "source": [
        "## Setting up Conda\n",
        "\n",
        "Bioinformatics pipelines often depend on many different software tools, each with its own specific version requirements. Managing these dependencies manually is extremely difficult.\n",
        "\n",
        "**Conda** is a package and environment manager that solves this problem. Nextflow can integrate directly with Conda, allowing it to automatically create isolated environments for each step of the pipeline and install the exact software versions needed.\n",
        "\n",
        "This cell uses `condacolab`, a small Python library, to install the Conda package manager directly into our Google Colab environment. The `-q` flag for `pip` means \\\"quiet,\\\" suppressing the installation output.\n",
        "\n",
        "After this cell runs, the Colab kernel will restart to activate the Conda installation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYeM8d99PT-z"
      },
      "outputs": [],
      "source": [
        "!pip install -q condacolab # -q here means quite\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kk9FMckIPUjp"
      },
      "outputs": [],
      "source": [
        "!conda config --add channels bioconda\n",
        "!conda config --add channels conda-forge\n",
        "!conda config --set channel_priority strict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sursu7ahPZSw"
      },
      "source": [
        "## Running a Test pipeline\n",
        "\n",
        "Before running our complex analysis, we'll test our environment with `nf-core/demo`, a simple pipeline designed for this purpose.\n",
        "\n",
        "The `nextflow pull` command (commented out here) downloads the pipeline's code and dependency definitions from the nf-core repository. This \"pulls\" the pipeline into the local Nextflow cache, which can make the subsequent `run` command start faster.\n",
        "\n",
        "**Note*: uncomment the next cells to run the Test*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMymtYBoO7Eb"
      },
      "outputs": [],
      "source": [
        "#! nextflow pull nf-core/demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IygCHi6ePtQv"
      },
      "outputs": [],
      "source": [
        "#! nextflow run nf-core/demo -profile conda,test --outdir demo-results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_2UONcTik6t"
      },
      "source": [
        "# Running Taxprofiler pipeline\n",
        "\n",
        "**nf-core/taxprofiler** is a bioinformatics best-practice analysis pipeline for taxonomic classification and profiling of shotgun short- and long-read metagenomic data. It allows for in-parallel taxonomic identification of reads or taxonomic abundance estimation with multiple classification and profiling tools against multiple databases, and produces standardised output tables for facilitating results comparison between different tools and databases.\n",
        "\n",
        "![image.png](https://raw.githubusercontent.com/Multiomics-Analytics-Group/course_multi-omics_data_science/refs/heads/main/metagenomics/notebooks/img/taxprofiler_tube.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK3h5HyYWa2G"
      },
      "source": [
        "### Creating Data Folders for Metagenomics Analysis\n",
        "\n",
        "Now we begin the setup for our real analysis. The first step is to create a structured set of directories to keep our files organized.\n",
        "\n",
        "* `!mkdir metagenomics`: Creates a main parent directory for the project.\n",
        "\n",
        "* `!mkdir metagenomics/data`: Creates a subdirectory to hold our raw sequencing data and the sample sheet.\n",
        "\n",
        "* `!mkdir metagenomics/databases`: Creates a subdirectory to hold our database configuration file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZRNWpZ_T2Ke"
      },
      "outputs": [],
      "source": [
        "!mkdir metagenomics\n",
        "!mkdir metagenomics/data\n",
        "!mkdir metagenomics/databases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tabULdAGWhtD"
      },
      "source": [
        "### Downloading Sample Sheet and Database File for nf-core/Taxprofiler\n",
        "\n",
        "The `nf-core/taxprofiler` pipeline requires two main configuration files to run:\n",
        "\n",
        "1.  **Sample Sheet**: This `sample_sheet.csv` file is the primary input. It's a table that tells the pipeline what samples to process and, critically, where to find their corresponding raw sequencing files (the forward and reverse reads). We use `wget` to download a pre-configured sample sheet and save it to `metagenomics/data/`.\n",
        "\n",
        "2.  **Database Sheet**: This `database_full_v1.2.csv` file tells Taxprofiler which taxonomic databases to use (e.g., Kraken2, MetaPhlAn) and what parameters to use when running them. We download this file and save it to `metagenomics/databases/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gyh474X9UtE2"
      },
      "outputs": [],
      "source": [
        "! wget https://raw.githubusercontent.com/Multiomics-Analytics-Group/course_multi-omics_data_science/refs/heads/main/metagenomics/data/sample_sheet.csv -O metagenomics/data/sample_sheet.csv\n",
        "! wget https://raw.githubusercontent.com/Multiomics-Analytics-Group/course_multi-omics_data_science/refs/heads/main/metagenomics/databases/database_full_v1.2.csv -O metagenomics/databases/database_full_v1.2.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viX5Y9EnbHCe"
      },
      "source": [
        "### Download Taxprofiler configuration\n",
        " \n",
        " Metagenomics analysis can be very computationally intensive, requiring large amounts of RAM and many CPUs. Since Google Colab provides a resource-limited environment, running the pipeline with its default settings (which are designed for servers or clusters) would likely cause it to crash.\n",
        " \n",
        " This command downloads a custom Nextflow configuration file named `low_resources.config`. This file contains settings that override the pipeline's defaults, instructing it to use less memory and fewer CPUs for each step. We will later pass this file to Nextflow using the `-c` flag."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXl5sLPeVVef"
      },
      "outputs": [],
      "source": [
        "! wget https://raw.githubusercontent.com/Multiomics-Analytics-Group/course_multi-omics_data_science/refs/heads/main/metagenomics/low_resources.config -O metagenomics/low_resources.config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDR1-9YAbNcn"
      },
      "source": [
        "### Downloading Raw Sequencing Data (FASTQ files) ðŸ’¾\n",
        "\n",
        "Download data from the [The Inflammatory Bowel Disease Multi'omics Database (IBDMdb)\n",
        "](https://ibdmdb.org/).\n",
        "\n",
        "All files can be found in the [Download Data](https://ibdmdb.org/results) option."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_yhItalcAdO"
      },
      "outputs": [],
      "source": [
        "# Sample HSMA33OT\n",
        "! wget https://g-227ca.190ebd.75bc.data.globus.org/ibdmdb/raw/HMP2/MGX/2018-05-04/HSMA33OT.tar -O metagenomics/data/HSMA33OT.tar\n",
        "! tar -xf metagenomics/data/HSMA33OT.tar -C metagenomics/data\n",
        "! rm metagenomics/data/HSMA33OT.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CW4E3y6biqBC"
      },
      "outputs": [],
      "source": [
        "# Sample CSM9X233\n",
        "! wget https://g-227ca.190ebd.75bc.data.globus.org/ibdmdb/raw/HMP2/MGX/2018-05-04/CSM9X233.tar -O metagenomics/data/CSM9X233.tar\n",
        "! tar -xf metagenomics/data/CSM9X233.tar -C metagenomics/data\n",
        "! rm  metagenomics/data/CSM9X233.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AC1rMoaadiLi"
      },
      "outputs": [],
      "source": [
        "# Sample CSM5MCWG\n",
        "! wget https://g-227ca.190ebd.75bc.data.globus.org/ibdmdb/raw/HMP2/MGX/2018-05-04/CSM5MCWG.tar -O metagenomics/data/CSM5MCWG.tar\n",
        "! tar -xf metagenomics/data/CSM5MCWG.tar -C metagenomics/data\n",
        "! rm  metagenomics/data/CSM5MCWG.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWGRy8bPdwkp"
      },
      "outputs": [],
      "source": [
        "# Sample MSMAPC7P\n",
        "! wget https://g-227ca.190ebd.75bc.data.globus.org/ibdmdb/raw/HMP2/MGX/2018-05-04/MSMAPC7P.tar -O metagenomics/data/MSMAPC7P.tar\n",
        "! tar -xf metagenomics/data/MSMAPC7P.tar -C metagenomics/data\n",
        "! rm  metagenomics/data/MSMAPC7P.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pulling the nf-core/rnaseq Pipeline Version\n",
        "\n",
        "This command uses `nextflow pull` to download and cache the latest version of the `nf-core/taxprofiler` pipeline locally. This ensures that the execution uses a defined, stable version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6ICyhGxilCO"
      },
      "outputs": [],
      "source": [
        "! nextflow pull nf-core/taxprofiler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG0i4NLAwZmX"
      },
      "source": [
        "### Executing the nf-core/taxprofiler Pipeline ðŸš€\n",
        "\n",
        "This is the final command that executes the entire `nf-core/taxprofiler` pipeline. Let's break down each argument:\n",
        "\n",
        "* `! nextflow run nf-core/taxprofiler`: The main command to run this specific pipeline.\n",
        "\n",
        "* `--input ./metagenomics/data/sample_sheet.csv`: Points the pipeline to our sample sheet. This is how it discovers the input files.\n",
        "\n",
        "* `--databases ./metagenomics/databases/database_full_v1.2.csv`: Points to our database configuration file.\n",
        "\n",
        "* `--outdir metagenomics/results`: Tells the pipeline to save all output files into a new directory named `metagenomics/results`.\n",
        "\n",
        "* `-profile conda`: Instructs Nextflow to use Conda for managing all software dependencies.\n",
        "\n",
        "* `-c metagenomics/low_resources.config`: Loads our custom configuration file (`-c`) to ensure the pipeline runs within Colab's memory and CPU limits.\n",
        "\n",
        "* `-resume`: This is a powerful Nextflow feature. If the pipeline is interrupted (e.g., Colab disconnects), you can run this exact same command again, and Nextflow will intelligently skip any steps that have already completed successfully, picking up right where it left off."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXGOe4ctjP-i"
      },
      "outputs": [],
      "source": [
        "! nextflow run nf-core/taxprofiler \\\n",
        "    --input ./metagenomics/data/sample_sheet.csv \\\n",
        "    --databases ./metagenomics/databases/database_full_v1.2.csv \\\n",
        "    --outdir metagenomics/results \\\n",
        "    -profile conda \\\n",
        "    -c metagenomics/low_resources.config \\\n",
        "    -resume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoL72Fyjr2GC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
